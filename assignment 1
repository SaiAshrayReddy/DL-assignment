import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import confusion_matrix

class NeuralNetwork(nn.Module):
    def __init__(self, input_dim=784, hidden_layers=[128, 64], output_dim=47, activation='relu'):
        super(NeuralNetwork, self).__init__()
        layers = []
        prev_dim = input_dim
        for hidden_dim in hidden_layers:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            if activation == 'relu':
                layers.append(nn.ReLU())
            elif activation == 'sigmoid':
                layers.append(nn.Sigmoid())
            prev_dim = hidden_dim
        layers.append(nn.Linear(prev_dim, output_dim))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

transformations = transforms.Compose([
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.view(-1))
])

full_train_data = datasets.EMNIST(root='./data', split='balanced', train=True, download=True, transform=transformations)
test_data = datasets.EMNIST(root='./data', split='balanced', train=False, download=True, transform=transformations)

train_size = int(0.9 * len(full_train_data))
val_size = len(full_train_data) - train_size
train_data, val_data = random_split(full_train_data, [train_size, val_size])

def get_data_loaders(batch_size):
    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)
    return train_loader, val_loader, test_loader
def adjust_labels(labels, num_classes):
    return labels % num_classes

def train_model(model, train_loader, val_loader, loss_function, optimizer, num_epochs=5, num_classes=47):
    model.train()
    for epoch in range(num_epochs):
        total_loss = 0
        for images, labels in train_loader:
            labels = adjust_labels(labels, num_classes)
            optimizer.zero_grad()
            predictions = model(images)
            loss = loss_function(predictions, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        avg_loss = total_loss / len(train_loader)
        print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {avg_loss:.4f}')
        evaluate_model(model, val_loader, num_classes)

def evaluate_model(model, data_loader, num_classes=47):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in data_loader:
            labels = adjust_labels(labels, num_classes)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    print(f'Validation Accuracy: {accuracy:.2f}%')
    return accuracy

def hyperparameter_search():
    hidden_layers_options = [[32, 32, 32], [64, 64, 64], [128, 128, 128]]
    batch_sizes = [16, 32, 64]
    optimizers = ['sgd', 'momentum', 'nesterov', 'rmsprop', 'adam']
    best_accuracy = 0
    best_model = None
    for hidden_layers in hidden_layers_options:
        for batch_size in batch_sizes:
            for opt in optimizers:
                train_loader, val_loader, test_loader = get_data_loaders(batch_size)
                model = NeuralNetwork(hidden_layers=hidden_layers)
                loss_function = nn.CrossEntropyLoss()
                if opt == 'sgd':
                    optimizer = optim.SGD(model.parameters(), lr=0.001)
                elif opt == 'momentum':
                    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
                elif opt == 'nesterov':
                    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)
                elif opt == 'rmsprop':
                    optimizer = optim.RMSprop(model.parameters(), lr=0.001)
                elif opt == 'adam':
                    optimizer = optim.Adam(model.parameters(), lr=0.001)
                print(f'Training with {hidden_layers} layers, batch {batch_size}, optimizer {opt}')
                train_model(model, train_loader, val_loader, loss_function, optimizer, num_epochs=5, num_classes=47)
                acc = evaluate_model(model, val_loader, num_classes=47)
                if acc > best_accuracy:
                    best_accuracy = acc
                    best_model = model
    print(f'Best model accuracy: {best_accuracy:.2f}%')
    return best_model, test_loader

best_model, test_loader = hyperparameter_search()
